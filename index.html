<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>VERA — Whisper (US)</title>
<style>
  :root{
    --bg:#060818;
    --ink:#e9ecff;
    --glass:rgba(255,255,255,.06);
    --glowA:#8ab4ff; --glowB:#b38bff; --glowC:#ffd2f3; --glowD:#a7ffeb;
    --accent:#9b87f5;
  }
  html,body{height:100%}
  body{
    margin:0; background: radial-gradient(1200px 900px at 50% 10%, #0b0f2a, var(--bg) 55%, #000 100%);
    color:var(--ink); font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Arial, "Apple Color Emoji","Segoe UI Emoji";
    overflow:hidden;
  }
  .hud{
    position:fixed; inset:16px auto auto 16px; z-index:5; display:flex; gap:10px; align-items:center;
    padding:10px 14px; border:1px solid var(--glass); border-radius:12px; background: linear-gradient(180deg, rgba(255,255,255,.06), rgba(255,255,255,.02));
    backdrop-filter: blur(10px);
  }
  .hud b{font-weight:600}
  .hud button, .hud select{
    appearance:none; border:1px solid var(--glass); background:rgba(255,255,255,.06); color:var(--ink);
    padding:8px 12px; border-radius:10px; cursor:pointer;
  }

  /* ORBIT */
  .wrap{position: absolute; inset:0; display:grid; place-items:center;}
  .field{position:relative; width:min(84vmin,720px); aspect-ratio:1/1; }
  .halo{
    position:absolute; inset:0; border-radius:50%;
    background:
      radial-gradient(120px 120px at 58% 38%, rgba(255,255,255,.15), transparent 60%),
      radial-gradient(800px 800px at 50% 85%, rgba(138,180,255,.06), transparent 70%),
      radial-gradient(600px 600px at 10% 10%, rgba(179,139,255,.08), transparent 60%),
      radial-gradient(600px 600px at 90% 10%, rgba(167,255,235,.08), transparent 60%);
    box-shadow:
      0 0 140px 40px rgba(138,180,255,.12) inset,
      0 0 220px 40px rgba(179,139,255,.10) inset;
    filter: saturate(1.1);
  }
  .nodes{
    position:absolute; inset:7% 7%; border-radius:50%;
    background:radial-gradient(closest-side, rgba(255,255,255,.12), transparent 70%);
    mask: radial-gradient(closest-side,#000 58%,transparent 59%), radial-gradient(farthest-side,#000 0,#000);
  }
  /* animated neuron dots */
  .dot{position:absolute; width:8px; height:8px; border-radius:50%;
    background: radial-gradient(circle, #fff 0, #fff 35%, transparent 36%);
    filter: drop-shadow(0 0 6px #fff);
  }
  /* their paths (CSS motion/path) */
  @keyframes orbitA { from{ offset-distance: 0%; } to{ offset-distance: 100%; } }
  /* speaking pulse */
  .pulse{
    position:absolute; inset:0; border-radius:50%;
    pointer-events:none; opacity:.0;
  }
  .speaking .pulse{
    animation: speakPulse 1.6s ease-in-out infinite;
  }
  @keyframes speakPulse {
    0%{ box-shadow: 0 0 0 0 rgba(155,135,245,.50), 0 0 40px 10px rgba(155,135,245,.25) inset; opacity:.85; filter:hue-rotate(0deg);}
    50%{ box-shadow: 0 0 0 32px rgba(167,255,235,0), 0 0 60px 20px rgba(255,210,243,.25) inset; opacity:.7; filter:hue-rotate(25deg);}
    100%{ box-shadow: 0 0 0 0 rgba(155,135,245,0), 0 0 40px 10px rgba(138,180,255,.25) inset; opacity:.85; filter:hue-rotate(50deg);}
  }
  /* listening shimmer */
  .listening .halo{
    animation: listenGlow 2.2s ease-in-out infinite;
  }
  @keyframes listenGlow{
    0%{ box-shadow: 0 0 140px 40px rgba(138,180,255,.14) inset, 0 0 220px 40px rgba(179,139,255,.10) inset; filter:hue-rotate(0deg) saturate(1.1);}
    50%{ box-shadow: 0 0 200px 70px rgba(167,255,235,.18) inset, 0 0 260px 60px rgba(255,210,243,.12) inset; filter:hue-rotate(30deg) saturate(1.25);}
    100%{ box-shadow: 0 0 140px 40px rgba(138,180,255,.14) inset, 0 0 220px 40px rgba(179,139,255,.10) inset; filter:hue-rotate(0deg) saturate(1.1);}
  }

  .cta{
    position: absolute; left:50%; top: calc(100% + 24px); transform: translateX(-50%);
    color:#cfd7ff; font-weight:500; font-size:14px; opacity:.85;
  }

  .status{
    position:fixed; inset:auto 16px 16px auto; padding:10px 14px; border:1px solid var(--glass);
    border-radius:12px; background:rgba(255,255,255,.05); backdrop-filter: blur(8px);
    font-size:13px; opacity:.85;
  }
</style>
</head>
<body>
  <div class="hud">
    <b>Voice:</b>
    <select id="engine">
      <option value="eleven" selected>ElevenLabs (US Whisper)</option>
      <option value="browser">Browser Fallback (en-US)</option>
    </select>
    <button id="test">Test Voice</button>
  </div>

  <div class="wrap">
    <div class="field" id="orbWrap">
      <div class="halo"></div>
      <div class="nodes" id="nodes"></div>
      <div class="pulse"></div>
      <div class="cta">Tap / click to talk to VERA • Tap again to stop</div>
    </div>
  </div>

  <div class="status" id="status">idle</div>

  <audio id="out" preload="auto"></audio>

<script>
(function(){
  const out = document.getElementById('out');
  const orbWrap = document.getElementById('orbWrap');
  const statusEl = document.getElementById('status');
  const engineSel = document.getElementById('engine');
  const testBtn = document.getElementById('test');

  function sayStatus(s){ statusEl.textContent = s; }

  // draw some neuron dots on curved paths
  const nodes = document.getElementById('nodes');
  const paths = [
    "path('M 50 260 C 160 40, 460 40, 570 260 S 460 480, 290 410 S 50 260, 50 260')",
    "path('M 80 140 C 210 40, 460 60, 520 210 S 410 380, 260 340 S 100 220, 80 140')",
    "path('M 150 460 C 320 380, 420 380, 510 460 S 450 520, 330 510 S 200 520, 150 460')",
    "path('M 120 300 C 220 160, 420 160, 560 300 S 450 420, 300 420 S 160 380, 120 300')"
  ];
  for (let i=0;i<26;i++){
    const d = document.createElement('div');
    d.className = 'dot';
    const p = paths[i % paths.length];
    d.style.offsetPath = p;
    d.style.offsetDistance = (Math.random()*100).toFixed(2)+'%';
    d.style.animation = `orbitA ${18 + Math.random()*12}s linear infinite`;
    d.style.filter = `drop-shadow(0 0 6px rgba(255,255,255,.5)) hue-rotate(${Math.floor(Math.random()*60)}deg)`;
    nodes.appendChild(d);
  }

  let listening = false;
  let speaking = false;
  let mediaStream; let mediaRecorder; let chunks = [];

  async function startMic(){
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(mediaStream);
    chunks = [];
    mediaRecorder.ondataavailable = (e)=>{ if(e.data.size>0) chunks.push(e.data); };
    mediaRecorder.onstop = handleUserAudio;
    mediaRecorder.start();
  }
  function stopMic(){
    if(mediaRecorder && mediaRecorder.state !== 'inactive'){ mediaRecorder.stop(); }
    if(mediaStream){ mediaStream.getTracks().forEach(t=>t.stop()); }
  }

  // Simple “understands” function (replace w/ your LLM later)
  function craftReply(userText){
    const t = (userText||"").toLowerCase();
    if (t.includes('anx') || t.includes('panic')) {
      return "I’m right here with you. Press your feet into the floor for two slow breaths. On a scale of one to ten, where is your charge now?";
    }
    if (t.includes('chest') || t.includes('tight')) {
      return "Place a hand on your chest. Let your shoulders drop one millimeter. Breathe around the edges of that sensation, not the center.";
    }
    if (t.includes('hello') || t.includes('hi')){
      return "Hi, love. I’m here. What’s alive in your body right now?";
    }
    return "I hear you. Where does this live in your body—front or back, left or right, surface or deep? Give me three words for its texture.";
  }

  // ---- Speech Out (primary: ElevenLabs; fallback: US browser TTS) ----
  async function speak(text, {preset="whisper"} = {}){
    try{
      if (engineSel.value === 'browser') throw new Error('force-fallback');
      const r = await fetch('/api/vera-voice', {
        method:'POST',
        headers:{'content-type':'application/json'},
        body: JSON.stringify({ text, stylePreset: preset })
      });
      if(!r.ok) throw new Error('tts-failed');
      const blob = await r.blob();
      const url = URL.createObjectURL(blob);
      out.src = url;
      await out.play();
      out.onended = () => { URL.revokeObjectURL(url); orbWrap.classList.remove('speaking'); speaking=false; sayStatus('idle'); };
      return;
    }catch(_){
      // Browser fallback → Make sure it is American English.
      const synth = window.speechSynthesis;
      const u = new SpeechSynthesisUtterance(text);
      u.rate = 0.93; u.pitch = 1.07; u.lang = 'en-US';

      function pickUSVoice(){
        const vs = synth.getVoices() || [];
        // strongly prefer en-US & feminine / warm names if present
        const prefer = vs.find(v => v.lang === 'en-US' && /female|samantha|us|ariel|serena|alloy|nova|america/i.test(v.name));
        if (prefer) return prefer;
        const anyUS = vs.find(v => v.lang === 'en-US');
        return anyUS || vs[0] || null;
      }
      function go(){
        u.voice = pickUSVoice();
        synth.cancel();
        synth.speak(u);
      }
      if (synth.getVoices().length === 0) {
        synth.onvoiceschanged = go;
      } else {
        go();
      }
      u.onend = ()=>{ orbWrap.classList.remove('speaking'); speaking=false; sayStatus('idle'); };
    }
  }

  // handle user mic blob → fake STT (quick demo), then reply
  async function handleUserAudio(){
    sayStatus('thinking');
    orbWrap.classList.remove('listening');

    // Demo STT: we won’t send audio anywhere; we just say “Hi” if short, else pretend.
    const len = chunks.reduce((n,b)=>n+b.size,0);
    let userText = len < 12000 ? "hi" : "my body feels anxious";
    try{
      // You can wire real STT here (OpenAI Whisper API or other).
      // POST chunks as a Blob to your own /api/stt, parse text → userText
    }catch{}

    const reply = craftReply(userText);
    speaking = true; orbWrap.classList.add('speaking'); sayStatus('speaking');
    await speak(reply, {preset:"whisper"});
  }

  // tap orbit → toggle listening
  orbWrap.addEventListener('click', async ()=>{
    if (speaking){ // interrupt
      out.pause(); out.currentTime = 0; window.speechSynthesis?.cancel();
      orbWrap.classList.remove('speaking'); speaking=false; sayStatus('idle'); return;
    }
    if(!listening){
      sayStatus('listening'); listening=true; orbWrap.classList.add('listening');
      await startMic();
    }else{
      sayStatus('processing'); listening=false; stopMic();
    }
  });

  // Test voice button
  testBtn.addEventListener('click', ()=>{
    speaking=true; orbWrap.classList.add('speaking'); sayStatus('speaking');
    speak("This is VERA in a soft American whisper. I'm right here with you. Breathe with me for four counts. One. Two. Three. Four.", {preset:"whisper"});
  });

})();
</script>
</body>
</html>
